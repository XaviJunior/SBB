{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet2_TBer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDZHlTULj-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr1O8BQpNRx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install spacy\n",
        "#!apt install -qq enchant\n",
        "#!pip install pyenchant\n",
        "#!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_CKOpStQK5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpDJQguPf4l8",
        "colab_type": "text"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyVmGGwCNTf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/XaviJunior/SBB/master/project_2/Data/train.csv',encoding=\"utf8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bR5ERBmNt5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=data['target']\n",
        "X=data['text']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0IynwlTORhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Text_train=X_train.values.tolist()\n",
        "Text_test=X_test.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-x212JRf6Zd",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aYwMlLkNoCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizer found in the DMML class lab 6.1\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pqCIjSCQesc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect=TfidfVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmJZ7nh6gAgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Clean_train=vect.transform(Text_train)\n",
        "Clean_test=vect.transform(Text_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhVd3R0Ldz-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test=pd.read_csv('https://raw.githubusercontent.com/XaviJunior/SBB/master/project_2/Data/test.csv',encoding='utf8')\n",
        "D=data_test['text']\n",
        "d=vect.fit_transform(D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-8nJzE869D8",
        "colab_type": "text"
      },
      "source": [
        "ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdf-2xhRTB7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RF = RandomForestClassifier(criterion=\"entropy\", n_estimators=51, max_depth=306, random_state=8)\n",
        "RF.fit(Clean_train,y_train)\n",
        "RF.score(Clean_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ77AI567Ni3",
        "colab_type": "text"
      },
      "source": [
        "First Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYnqLEul7KUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=RF.predict(d)\n",
        "data_test['target']=pred\n",
        "Fin=data_test[['id','target']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YKdU8yy7Szd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "Fin.to_csv('UNIL_SBB_1st.csv',index=False)\n",
        "!cp UNIL_SBB_1st.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2pMQLvx7TbZ",
        "colab_type": "text"
      },
      "source": [
        "Result = 0.77811\n",
        "Rank=1763"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CPA8zOD7hrz",
        "colab_type": "text"
      },
      "source": [
        "Random Forest Optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj1SjLjo7gUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "113f52c1-2d02-4ae0-8a19-a4cb5474970d"
      },
      "source": [
        "a=0\n",
        "for i in range(11,500,2):\n",
        "  for j in range(50,200):\n",
        "    RF_2 = RandomForestClassifier(criterion=\"entropy\", n_estimators=i, max_depth=j, random_state=8)\n",
        "    RF_2.fit(Clean_train,y_train)\n",
        "    if RF_2.score(Clean_test,y_test)>a:\n",
        "      a=RF_2.score(Clean_test,y_test)\n",
        "      print(a,' ',i,' ',j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7393302692055155   11   50\n",
            "0.7498358502954695   11   51\n",
            "0.7511490479317138   11   53\n",
            "0.7518056467498359   11   57\n",
            "0.7550886408404465   11   58\n",
            "0.7564018384766907   11   64\n",
            "0.757715036112935   11   69\n",
            "0.762967826657912   11   74\n",
            "0.7655942219304005   11   80\n",
            "0.767564018384767   11   86\n",
            "0.7688772160210111   11   92\n",
            "0.7695338148391333   11   110\n",
            "0.7701904136572554   11   116\n",
            "0.7747866053841103   11   119\n",
            "0.7800393959290873   11   132\n",
            "0.7806959947472094   11   144\n",
            "0.7826657912015759   11   152\n",
            "0.783322390019698   11   165\n",
            "0.7839789888378201   11   170\n",
            "0.7846355876559422   11   179\n",
            "0.7852921864740644   11   183\n",
            "0.7898883782009193   11   197\n",
            "0.7918581746552856   13   170\n",
            "0.7951411687458962   15   170\n",
            "0.7957977675640184   23   176\n",
            "0.7971109652002626   25   186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAcKTeajNy27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdpTqVPgBq1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=0\n",
        "e=0\n",
        "d=0\n",
        "for i in range(103,500,2):\n",
        "  for j in range(10,500):\n",
        "    xgc = xgb.XGBClassifier(n_estimators=i, max_depth=j, base_score=0.5, objective='binary:logistic', random_state=42)\n",
        "    xgc.fit(Clean_train,y_train)\n",
        "    if xgc.score(Clean_test,y_test)>a:\n",
        "      a=xgc.score(Clean_test,y_test)\n",
        "      print(a,' ',i,' ',j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE9ERNMONVIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.7957977675640184   101   71\n",
        "0.7806959947472094   101   60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbpZvzvPd5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIWeSkP0zH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c17a846c-2881-4ffd-cc5f-df0e66a25038"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "Fin.to_csv('UNIL_SBB_1st.csv',index=False)\n",
        "!cp UNIL_SBB_1st.csv \"drive/My Drive/\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQVAgLKIPPg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([\n",
        "('vect', vect),\n",
        "#('tfidf', TfidfTransformer()),\n",
        "('clf',MultinomialNB()),])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQsHqN2JPnEt",
        "colab_type": "code",
        "outputId": "c6155b3b-3a28-458c-fa58-192e42cdc4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_clf.fit(Text_train, y_train)\n",
        "print(text_clf.score(Text_test,y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8102429415627052\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}